{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file that includes your answers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mJpzFaX0J6Zz",
        "outputId": "33e49695-d65f-4948-f0ea-057c6f3ad787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mHomework by Victoria Yong, number: 1004455\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004455\"\n",
        "student_name=\"Victoria Yong\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- matrix multiplication\n",
        "\n",
        "Implement the following mathematical operation on both the CPU and GPU (use Google Colab or another cloud service if you don't have a GPU in your computer). Print:\n",
        "\n",
        "a) which type of GPU card you have and \n",
        "\n",
        "b) show the computation time for both CPU and GPU (using PyTorch). \n",
        "\n",
        "c) How much % faster is the GPU? \n",
        "\n",
        " The operation to implement is the dot product $C = B * A^T$\n",
        "\n",
        " whereby $A$ is a random matrix of size $20,000 \\times 1,000$ and $B$ is a random matrix of size $2,000 \\times 1,000$. In addition to the required information asked above:\n",
        " \n",
        " d) please also print the resulting two $C$ matrices (they should be the same btw). \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA GeForce RTX 3060 Ti\n"
          ]
        }
      ],
      "source": [
        "# implement solution here\n",
        "print(torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU:  161.50930786132812\n",
            "tensor([[263.2691, 257.2154, 253.2079,  ..., 252.6945, 259.6516, 251.9566],\n",
            "        [253.8056, 254.6681, 253.5869,  ..., 236.7095, 255.4012, 246.2735],\n",
            "        [252.6508, 253.7045, 252.9636,  ..., 244.9855, 251.5641, 247.7907],\n",
            "        ...,\n",
            "        [255.4564, 253.3973, 255.3647,  ..., 244.7879, 254.4832, 246.4949],\n",
            "        [260.1990, 257.9343, 255.4839,  ..., 247.3258, 258.9628, 249.9205],\n",
            "        [247.3627, 248.4945, 251.4022,  ..., 231.2974, 250.6243, 243.7911]])\n",
            "GPU:  169.88336181640625\n",
            "tensor([[263.2691, 257.2154, 253.2079,  ..., 252.6945, 259.6516, 251.9566],\n",
            "        [253.8056, 254.6681, 253.5869,  ..., 236.7095, 255.4012, 246.2735],\n",
            "        [252.6508, 253.7045, 252.9636,  ..., 244.9855, 251.5641, 247.7907],\n",
            "        ...,\n",
            "        [255.4564, 253.3973, 255.3647,  ..., 244.7879, 254.4832, 246.4949],\n",
            "        [260.1990, 257.9343, 255.4839,  ..., 247.3258, 258.9628, 249.9205],\n",
            "        [247.3627, 248.4945, 251.4022,  ..., 231.2974, 250.6243, 243.7911]])\n",
            "GPU is faster by 4.929296115606662%\n"
          ]
        }
      ],
      "source": [
        "cpu_start = torch.cuda.Event(enable_timing=True)\n",
        "cpu_end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "A = torch.rand((20000, 1000)).to('cpu')\n",
        "b = torch.rand((2000, 1000)).to('cpu')\n",
        "\n",
        "## CPU\n",
        "cpu_start.record()\n",
        "c = b@A.t()\n",
        "cpu_end.record()\n",
        "\n",
        "# Waits for everything to finish running\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "cpu_time = cpu_start.elapsed_time(cpu_end)\n",
        "\n",
        "print('CPU: ', cpu_time)\n",
        "print(c)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "## GPU\n",
        "gpu_start = torch.cuda.Event(enable_timing=True)\n",
        "gpu_end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "A.cuda()\n",
        "b.cuda()\n",
        "\n",
        "gpu_start.record()\n",
        "c = b@A.t()\n",
        "gpu_end.record()\n",
        "\n",
        "# Waits for everything to finish running\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "gpu_time = gpu_start.elapsed_time(gpu_end)\n",
        "print('GPU: ', gpu_time)\n",
        "print(c)\n",
        "\n",
        "print(f\"GPU is faster by {(gpu_time - cpu_time)/gpu_time*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJXmfT-yU3g"
      },
      "source": [
        "## Question 2 - grad\n",
        "\n",
        "\n",
        "Find the gradient (partial derivatives) of the function $g(w)$ below. \n",
        "\n",
        "Let  $w=[w_1,w_2]^T$\n",
        "\n",
        "Consider  $g(w)=2w_1w_2+w_2cos(w_1)$\n",
        "\n",
        "a) In PyTorch, compute:   $\\nabla g(w)$ \n",
        "\n",
        " and verify that $\\nabla g([\\pi,1])=[2,2\\piâˆ’1]^T$ using the grad function, whereby the first position is the partial for $w_1$ and the second position is the partial for $w_2$. \n",
        "\n",
        "b) You can also write a function to manually calculate these partial derivatives! You can review your differential equations math at [here](https://www.wolframalpha.com/input/?i=derivative+y+cos%28x%29) and implement this as a second function below to verify that it comes to the same solution. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pLjz6_LKt4sc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autograd Partial Differentiation : (tensor([[2.0000],\n",
            "        [5.2832]]),)\n",
            "Manual partial differntiation : tensor([2.0000, 5.2832])\n"
          ]
        }
      ],
      "source": [
        "# write your solution here\n",
        "w = torch.tensor([np.pi,1.],requires_grad=True).reshape(-1,1)\n",
        "g_w = 2 * w[0] * w[1]  + w[1] * torch.cos(w[0])\n",
        "\n",
        "dw_auto = torch.autograd.grad(g_w, w)\n",
        "print(f'Autograd Partial Differentiation : {dw_auto}')\n",
        "\n",
        "dw1 = 2 * w[1] - torch.sin(w[0])*w[1]\n",
        "dw2 = 2 * w[0] + torch.cos(w[0])\n",
        "\n",
        "dw_manual = torch.Tensor([dw1,dw2])\n",
        "print(f'Manual partial differntiation : {dw_manual}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwP6ur8LKjD"
      },
      "source": [
        "## Question 3 - dance hit song prediction\n",
        "\n",
        "Implement logistic regression in PyTorch for the following dance hit song prediction training dataset: \n",
        "https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "\n",
        " * Input variables: a number of audio features (most already standardized so don't worry about that)\n",
        " * Target variable: Topclass1030: \n",
        "   * 1 means it was a top 10 hit song; \n",
        "   * 0 means it never went above top 30 position.\n",
        "\n",
        "This dataset is derived from my paper on dance hit song prediction, for full description of features have a look at https://arxiv.org/abs/1905.08076. \n",
        "\n",
        "Print the evolution of the loss every few epochs and train the model until it converges. \n",
        " \n",
        " After training the logistic regression model, calculate the prediction accuracy on the test set: \n",
        " https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VyRP6bl8t4Wc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16472\\724039460.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  train_feats = train_data.drop('Topclass1030', 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\t Loss: 0.8439046144485474\n",
            "Epoch: 10\t Loss: 0.5644068121910095\n",
            "Epoch: 20\t Loss: 0.4772292375564575\n",
            "Epoch: 30\t Loss: 0.42795199155807495\n",
            "Epoch: 40\t Loss: 0.39873531460762024\n",
            "Epoch: 50\t Loss: 0.3798719346523285\n",
            "Epoch: 60\t Loss: 0.36710214614868164\n",
            "Epoch: 70\t Loss: 0.35813388228416443\n",
            "Epoch: 80\t Loss: 0.35175463557243347\n",
            "Epoch: 90\t Loss: 0.3472670018672943\n",
            "Epoch: 100\t Loss: 0.3439001739025116\n",
            "Epoch: 110\t Loss: 0.34153133630752563\n",
            "Epoch: 120\t Loss: 0.33975327014923096\n",
            "Epoch: 130\t Loss: 0.3387387692928314\n",
            "Epoch: 140\t Loss: 0.3380681574344635\n",
            "Epoch: 150\t Loss: 0.3379520773887634\n",
            "Epoch: 160\t Loss: 0.3377499282360077\n",
            "Epoch: 170\t Loss: 0.3376959562301636\n",
            "Epoch: 180\t Loss: 0.3381713628768921\n",
            "Epoch: 190\t Loss: 0.3390369713306427\n"
          ]
        }
      ],
      "source": [
        "# load train_data\n",
        "train_url = 'https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv'\n",
        "test_url = 'https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_url)\n",
        "train_labels = train_data['Topclass1030']\n",
        "train_feats = train_data.drop('Topclass1030', 1)\n",
        "\n",
        "# define logistic regression model\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        " \n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "   \n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    out = torch.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "# train model\n",
        "num_outputs = 1\n",
        "num_input_features = train_data.shape[1] - 1\n",
        "model = LogisticRegression(num_input_features, num_outputs).cuda()\n",
        "\n",
        "lr_rate = 0.001  # alpha\n",
        "loss_function = nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "epochs = 200 \n",
        "\n",
        "for i in range(epochs):\n",
        "    for j in range(train_data.shape[0]):\n",
        "        feats = torch.tensor(train_feats.loc[j].values).float().cuda()\n",
        "        label = torch.tensor([train_labels.loc[j]]).float().cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(feats)\n",
        "\n",
        "        loss = loss_function(pred, label).cuda() \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print (f\"Epoch: {i}\\t Loss: {loss.data.cpu().numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4yfGoGuChe"
      },
      "source": [
        "Run the below code to test the accuracy of your model on the training set: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L88WmKtMt5gH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positives: 39, True Negatives: 20\n",
            "False Positives: 9, False Negatives: 11\n",
            "Class specific accuracy of correctly predicting a hit song is 0.78\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "\n",
        "test = pd.read_csv(test_url)\n",
        "labels = test.iloc[:,-1]\n",
        "test = test.drop('Topclass1030', axis=1)\n",
        "testdata = torch.Tensor(test.values)\n",
        "testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FN = 0\n",
        "FP = 0\n",
        "\n",
        "for i in range(0, testdata.size()[0]): \n",
        "  # print(testdata[i].size())\n",
        "  Xtest = torch.Tensor(testdata[i]).cuda()\n",
        "  y_hat = model(Xtest)\n",
        "  \n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  if (prediction == testlabels[i]):\n",
        "    if (prediction == 1):\n",
        "      TP += 1\n",
        "    else: \n",
        "      TN += 1\n",
        "\n",
        "  else:\n",
        "    if (prediction == 1):\n",
        "      FP += 1\n",
        "    else: \n",
        "      FN += 1\n",
        "\n",
        "print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "rate = TP/(FN+TP)\n",
        "print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Week 5 - AI homework - torch intro",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('CV')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "a74aa4d0a99eacba0689de25ffa0dd97bae15bd34a3b5b1a3e697267974fb3f3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
