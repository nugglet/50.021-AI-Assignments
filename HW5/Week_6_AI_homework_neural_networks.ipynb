{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 2: neural networks\n",
        "\n",
        "-- Prof. Dorien Herremans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file on eDimension that includes your answers [so after you run it]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mJpzFaX0J6Zz",
        "outputId": "33e49695-d65f-4948-f0ea-057c6f3ad787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mHomework by Victoria Yong, number: 1004455\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004455\"\n",
        "student_name=\"Victoria Yong\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- XOR neural network [3pts]\n",
        "\n",
        "a) Train an (at least) 2-layer neural network that can solve the XOR problem. Hint: be sure to check both this week and last week's lab. \n",
        "\n",
        "b) Check the predictions resulting from your model in the second code box below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 5.206602096557617, \n",
            "Epoch: 1000, Loss: 0.12951618432998657, \n",
            "Epoch: 2000, Loss: 0.015476944856345654, \n",
            "Epoch: 3000, Loss: 0.0019497793400660157, \n",
            "Epoch: 4000, Loss: 0.00011420901864767075, \n"
          ]
        }
      ],
      "source": [
        "# load your data\n",
        "features = torch.Tensor([[0, 0],\n",
        "                        [0, 1],\n",
        "                        [1, 0],\n",
        "                        [1, 1]])\n",
        "labels = torch.Tensor([[0, 1, 1, 0]]).view(-1, 1)\n",
        "\n",
        "in_dim = features.size(1)\n",
        "\n",
        "# name your model xor\n",
        "def xor(epochs, feats, labels, in_dim, out_dim=1):\n",
        "# define your model loss function, optimizer, etc. \n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(in_dim, 128),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(128, out_dim),\n",
        "        nn.Sigmoid()\n",
        "    ).cuda()\n",
        "\n",
        "    loss_func = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # initialize weights\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 1)\n",
        "    \n",
        "    # train the model\n",
        "    for epoch in range(epochs):\n",
        "        for j in range(feats.size(0)):\n",
        "            idx = np.random.randint(feats.size(0))\n",
        "            x = torch.autograd.Variable(feats[idx], requires_grad=False).cuda()\n",
        "            y = torch.autograd.Variable(labels[idx], requires_grad=False).cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(x)\n",
        "            loss = loss_func(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"Epoch: {epoch}, Loss: {loss.cpu().data.numpy()}, \")\n",
        "    \n",
        "xor(5000, features, labels, in_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "51Ra1T6n2r_R"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "xor() missing 3 required positional arguments: 'feats', 'labels', and 'in_dim'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18024\\2626410795.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mXtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: xor() missing 3 required positional arguments: 'feats', 'labels', and 'in_dim'"
          ]
        }
      ],
      "source": [
        "# test your model using the following functions (make sure the output is printed and saved when you submit this notebook):\n",
        "# depending on how you defined your network you may need to slightly tweek the below prediction function\n",
        "\n",
        "test = [[0,0],[0,1],[1,1],[1,0]]\n",
        "\n",
        "for trial in test: \n",
        "  Xtest = torch.Tensor(trial)\n",
        "  y_hat = xor(Xtest)\n",
        "\n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  print(\"{0} xor {1} = {2}\".format(int(Xtest[0]), int(Xtest[1]), prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqIqD5ZzyUOW"
      },
      "source": [
        "## Question 2  [2pts]\n",
        "\n",
        "Imagine a neural network model for a multilabel classification task. \n",
        "\n",
        "a) Which loss function should you use?\n",
        "\n",
        "b) The resulting trained modal has a high variance error. Give 4 possible solutions to improve the model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzye9G18PQ0c"
      },
      "source": [
        "```\n",
        "[your answer here, no coding required]\n",
        "\n",
        "* answer A\n",
        "* answer B\n",
        "  - 1\n",
        "  - 2\n",
        "  - ...\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcceOSnjjSHf"
      },
      "source": [
        "## Question 3 - Improve hit classification [5pts]\n",
        "\n",
        "Remember the hit predicton dataset from last week? \n",
        "\n",
        "a) Improve the model using a multiplayer perceptron. \n",
        "\n",
        "b) Make sure to run your models on the GPU. \n",
        "\n",
        "c) Tweek the hyperparameters such as number of nodes or layers, or other. Show two possible configurations and explain which works better and very briefly explain why this may be the case. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-jkJDTdjSRX"
      },
      "outputs": [],
      "source": [
        "# code your model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIDPTKcFkETc"
      },
      "outputs": [],
      "source": [
        "# evaluate model 1 (called model1 here)\n",
        "\n",
        "\n",
        "TP import pandas as pd \n",
        "\n",
        "def run_evaluation(my_model):\n",
        "\n",
        "  test = pd.read_csv('/content/herremans_hit_1030test.csv')\n",
        "  labels = test.iloc[:,-1]\n",
        "  test = test.drop('Topclass1030', axis=1)\n",
        "  testdata = torch.Tensor(test.values)\n",
        "  testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FN = 0\n",
        "  FP = 0\n",
        "\n",
        "  for i in range(0, testdata.size()[0]): \n",
        "    # print(testdata[i].size())\n",
        "    Xtest = torch.Tensor(testdata[i])\n",
        "    y_hat = my_model(Xtest)\n",
        "    \n",
        "    if y_hat > 0.5:\n",
        "      prediction = 1\n",
        "    else: \n",
        "      prediction = 0\n",
        "\n",
        "    if (prediction == testlabels[i]):\n",
        "      if (prediction == 1):\n",
        "        TP += 1\n",
        "      else: \n",
        "        TN += 1\n",
        "\n",
        "    else:\n",
        "      if (prediction == 1):\n",
        "        FP += 1\n",
        "      else: \n",
        "        FN += 1\n",
        "\n",
        "  print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "  print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "  rate = TP/(FN+TP)\n",
        "  print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))\n",
        "\n",
        "run_evaluation(model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xghPDDNmkHn2"
      },
      "outputs": [],
      "source": [
        "# code your model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAIifiHJkHyW"
      },
      "outputs": [],
      "source": [
        "# evaluate model 2 (called model2 here)\n",
        "\n",
        "run_evaluation(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPsxbT0KkGs1"
      },
      "source": [
        "Which works better and why do you think this may be (very briefly)? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzjI77HkSwH"
      },
      "source": [
        "**[your answer here, also please summarise the differences between your two models]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh5O8qS_khug"
      },
      "source": [
        "Additionally, submit your results [here](https://forms.gle/NtJJEE7Wm5ZRM3Je7) for 'Class specific accuracy of correctly predicting a hit song' and see if you got the best performance of the class! Good luck!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Week 6 - AI homework - neural networks",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('CV')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "a74aa4d0a99eacba0689de25ffa0dd97bae15bd34a3b5b1a3e697267974fb3f3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
