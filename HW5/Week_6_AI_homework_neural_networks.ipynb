{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 2: neural networks\n",
        "\n",
        "-- Prof. Dorien Herremans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file on eDimension that includes your answers [so after you run it]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mJpzFaX0J6Zz",
        "outputId": "33e49695-d65f-4948-f0ea-057c6f3ad787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mHomework by Victoria Yong, number: 1004455\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004455\"\n",
        "student_name=\"Victoria Yong\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- XOR neural network [3pts]\n",
        "\n",
        "a) Train an (at least) 2-layer neural network that can solve the XOR problem. Hint: be sure to check both this week and last week's lab. \n",
        "\n",
        "b) Check the predictions resulting from your model in the second code box below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.0027467745821923018, \n",
            "Epoch: 100, Loss: 0.5857964754104614, \n",
            "Epoch: 200, Loss: 0.3704299330711365, \n",
            "Epoch: 300, Loss: 0.7951344847679138, \n",
            "Epoch: 400, Loss: 0.3863573670387268, \n",
            "Epoch: 500, Loss: 0.3926236629486084, \n",
            "Epoch: 600, Loss: 0.3062394857406616, \n",
            "Epoch: 700, Loss: 0.20453286170959473, \n",
            "Epoch: 800, Loss: 0.18820373713970184, \n",
            "Epoch: 900, Loss: 0.18948961794376373, \n"
          ]
        }
      ],
      "source": [
        "# load your data\n",
        "feats = torch.Tensor([[0, 0],\n",
        "                        [0, 1],\n",
        "                        [1, 0],\n",
        "                        [1, 1]])\n",
        "labels = torch.Tensor([[0, 1, 1, 0]]).view(-1, 1)\n",
        "\n",
        "in_dim = feats.size(1)\n",
        "\n",
        "# name your model xor\n",
        "def xor(in_dim=4, out_dim=1):\n",
        "# define your model loss function, optimizer, etc. \n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(in_dim, 128),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(128, out_dim),\n",
        "        nn.Sigmoid()\n",
        "    ).cuda()\n",
        "\n",
        "# initialize weights\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "#########################################################################################\n",
        "\n",
        "model = xor(in_dim)\n",
        "epochs = 1000\n",
        "\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# train the model\n",
        "for epoch in range(epochs):\n",
        "    for j in range(feats.size(0)):\n",
        "        idx = np.random.randint(feats.size(0))\n",
        "        x = torch.autograd.Variable(feats[idx], requires_grad=False).cuda()\n",
        "        y = torch.autograd.Variable(labels[idx], requires_grad=False).cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = loss_func(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch}, Loss: {loss.cpu().data.numpy()}, \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "51Ra1T6n2r_R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 xor 0 = 0\n",
            "0 xor 1 = 1\n",
            "1 xor 1 = 0\n",
            "1 xor 0 = 1\n"
          ]
        }
      ],
      "source": [
        "# test your model using the following functions (make sure the output is printed and saved when you submit this notebook):\n",
        "# depending on how you defined your network you may need to slightly tweek the below prediction function\n",
        "\n",
        "test = [[0,0],[0,1],[1,1],[1,0]]\n",
        "\n",
        "for trial in test: \n",
        "  Xtest = torch.Tensor(trial).cuda()\n",
        "  y_hat = model(Xtest)\n",
        "\n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  print(\"{0} xor {1} = {2}\".format(int(Xtest[0]), int(Xtest[1]), prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqIqD5ZzyUOW"
      },
      "source": [
        "## Question 2  [2pts]\n",
        "\n",
        "Imagine a neural network model for a multilabel classification task. \n",
        "\n",
        "a) Which loss function should you use?\n",
        "\n",
        "b) The resulting trained modal has a high variance error. Give 4 possible solutions to improve the model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzye9G18PQ0c"
      },
      "source": [
        "```\n",
        "a) Binary Cross Entropy Loss\n",
        "\n",
        "b) \n",
        "- 1 : Add dropout layers\n",
        "- 2 : Use data augmentation on training data\n",
        "- 3 : Implement early stopping\n",
        "- 4 : Get more training data that is balanced across classes\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcceOSnjjSHf"
      },
      "source": [
        "## Question 3 - Improve hit classification [5pts]\n",
        "\n",
        "Remember the hit predicton dataset from last week? \n",
        "\n",
        "a) Improve the model using a multiplayer perceptron. \n",
        "\n",
        "b) Make sure to run your models on the GPU. \n",
        "\n",
        "c) Tweek the hyperparameters such as number of nodes or layers, or other. Show two possible configurations and explain which works better and very briefly explain why this may be the case. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_17296\\1418662058.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  train_feats = train_data.drop('Topclass1030', 1)\n"
          ]
        }
      ],
      "source": [
        "# load train_data\n",
        "train_url = 'https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv'\n",
        "test_url = 'https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_url)\n",
        "train_labels = train_data['Topclass1030']\n",
        "train_feats = train_data.drop('Topclass1030', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t-jkJDTdjSRX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\t Loss: 0.6931471824645996\n",
            "Epoch: 10\t Loss: 0.7532297968864441\n",
            "Epoch: 20\t Loss: 0.7110101580619812\n",
            "Epoch: 30\t Loss: 0.6931471824645996\n",
            "Epoch: 40\t Loss: 0.6931471824645996\n"
          ]
        }
      ],
      "source": [
        "# code your model 1\n",
        "\n",
        "# MLP\n",
        "class MLP(nn.Module):\n",
        " \n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 64)\n",
        "    self.fc2 = nn.Linear(64, 16)\n",
        "    self.fc3 = nn.Linear(16, num_classes)\n",
        "   \n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = torch.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = torch.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    out = torch.relu(out)\n",
        "    out = torch.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "# train model\n",
        "num_outputs = 1\n",
        "num_input_features = train_data.shape[1] - 1\n",
        "model1 = MLP(num_input_features, num_outputs).cuda()\n",
        "\n",
        "lr_rate = 1e-3\n",
        "loss_function = nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=lr_rate)\n",
        "epochs = 50 \n",
        "\n",
        "for i in range(epochs):\n",
        "  for j in range(train_data.shape[0]):\n",
        "      feats = torch.tensor(train_feats.loc[j].values).float().cuda()\n",
        "      label = torch.tensor([train_labels.loc[j]]).float().cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      pred = model1(feats)\n",
        "\n",
        "      loss = loss_function(pred, label).cuda() \n",
        "      loss.backward() \n",
        "      optimizer.step() \n",
        "\n",
        "  if i % 10 == 0:\n",
        "      print (f\"Epoch: {i}\\t Loss: {loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UIDPTKcFkETc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positives: 42, True Negatives: 17\n",
            "False Positives: 12, False Negatives: 8\n",
            "Class specific accuracy of correctly predicting a hit song is 0.84\n"
          ]
        }
      ],
      "source": [
        "# evaluate model 1 (called model1 here)\n",
        "import pandas as pd \n",
        "\n",
        "def run_evaluation(my_model):\n",
        "\n",
        "  test = pd.read_csv(test_url)\n",
        "  labels = test.iloc[:,-1]\n",
        "  test = test.drop('Topclass1030', axis=1)\n",
        "  testdata = torch.Tensor(test.values)\n",
        "  testlabels = torch.Tensor(labels.values).view(-1,1).cuda()\n",
        "\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FN = 0\n",
        "  FP = 0\n",
        "\n",
        "  for i in range(0, testdata.size()[0]): \n",
        "    # print(testdata[i].size())\n",
        "    Xtest = torch.Tensor(testdata[i]).cuda()\n",
        "    y_hat = my_model(Xtest)\n",
        "    \n",
        "    if y_hat > 0.5:\n",
        "      prediction = 1\n",
        "    else: \n",
        "      prediction = 0\n",
        "\n",
        "    if (prediction == testlabels[i]):\n",
        "      if (prediction == 1):\n",
        "        TP += 1\n",
        "      else: \n",
        "        TN += 1\n",
        "\n",
        "    else:\n",
        "      if (prediction == 1):\n",
        "        FP += 1\n",
        "      else: \n",
        "        FN += 1\n",
        "\n",
        "  print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "  print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "  rate = TP/(FN+TP)\n",
        "  print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))\n",
        "\n",
        "run_evaluation(model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xghPDDNmkHn2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\t Loss: 0.763859212398529\n",
            "Epoch: 10\t Loss: 0.6931471824645996\n",
            "Epoch: 20\t Loss: 0.8280501961708069\n",
            "Epoch: 30\t Loss: 0.9652078151702881\n",
            "Epoch: 40\t Loss: 0.836501955986023\n",
            "Epoch: 50\t Loss: 0.805893063545227\n",
            "Epoch: 60\t Loss: 0.9505552649497986\n",
            "Epoch: 70\t Loss: 0.850154459476471\n",
            "Epoch: 80\t Loss: 0.7896213531494141\n",
            "Epoch: 90\t Loss: 0.8565614223480225\n"
          ]
        }
      ],
      "source": [
        "# code your model 2\n",
        "\n",
        "class MLP2(nn.Module):\n",
        " \n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(MLP2, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 32)\n",
        "    self.fc2 = nn.Linear(32, 8)\n",
        "    self.fc3 = nn.Linear(8, num_classes)\n",
        "    self.dropout = nn.Dropout(p=0.75)\n",
        "   \n",
        "  def init_weights(self):\n",
        "      # initialize weights\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              m.weight.data.normal_(0, 1)\n",
        "              \n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = torch.relu(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc2(out)\n",
        "    out = torch.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    out = torch.relu(out)\n",
        "    out = torch.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "# train model\n",
        "num_outputs = 1\n",
        "num_input_features = train_data.shape[1] - 1\n",
        "model2 = MLP2(num_input_features, num_outputs).cuda()\n",
        "\n",
        "lr_rate = 1e-4\n",
        "loss_function = nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=lr_rate, weight_decay=5e-4)\n",
        "\n",
        "epochs = 100 \n",
        "\n",
        "for i in range(epochs):\n",
        "    for j in range(train_data.shape[0]):\n",
        "        feats = torch.tensor(train_feats.loc[j].values).float().cuda()\n",
        "        label = torch.tensor([train_labels.loc[j]]).float().cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model2(feats)\n",
        "\n",
        "        loss = loss_function(pred, label).cuda() \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print (f\"Epoch: {i}\\t Loss: {loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wAIifiHJkHyW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positives: 50, True Negatives: 0\n",
            "False Positives: 29, False Negatives: 0\n",
            "Class specific accuracy of correctly predicting a hit song is 1.0\n"
          ]
        }
      ],
      "source": [
        "# evaluate model 2 (called model2 here)\n",
        "\n",
        "run_evaluation(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPsxbT0KkGs1"
      },
      "source": [
        "Which works better and why do you think this may be (very briefly)? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzjI77HkSwH"
      },
      "source": [
        "**[your answer here, also please summarise the differences between your two models]**\n",
        "\n",
        "From the evaluation, model 2 seemed to perfodrm better. Model 1 was a basic multilayer perceptron with 1 input layer, 1 output layer, and 1 hidden layer. The model uses the ReLu activation function to add non-linearities, and the final output is passed through a sigmoid function for binary classification. Model 2 adds a dropout layer with probability 0.75 and trains the model for twice the number of epochs as model 1. \n",
        "\n",
        "The dropout layer randomly assigns certain weights to 0, which helps to prevent overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh5O8qS_khug"
      },
      "source": [
        "Additionally, submit your results [here](https://forms.gle/NtJJEE7Wm5ZRM3Je7) for 'Class specific accuracy of correctly predicting a hit song' and see if you got the best performance of the class! Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Week 6 - AI homework - neural networks",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "ef92e30b963217edf8c11f058cfcd3463da60128b43c8003f4b632a507dd4936"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
